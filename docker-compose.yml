version: '3.8'

services:
  webserver:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ai-infra-guard-webserver
    ports:
      - "8088:8088"
    environment:
      - APP_ENV=production
      - UPLOAD_DIR=/ai-infra-guard/uploads
      - DB_PATH=/ai-infra-guard/db/tasks.db
      - TZ=Asia/Shanghai
      # 新增：默认模型配置
      - OPENAI_MODEL=gpt-3.5-turbo
      - OPENAI_API_KEY=your_openai_api_key
      - OPENAI_BASE_URL=https://api.openai.com/v1
    volumes:
      - ./data:/ai-infra-guard/data
      - ./db:/ai-infra-guard/db
      - ./logs:/ai-infra-guard/logs
      - ./uploads:/ai-infra-guard/uploads
    networks:
      - ai-infra-guard-network
    restart: always
    healthcheck:
      test: [ "CMD", "curl",  "http://localhost:8088/" ]
      interval: 30s
      timeout: 3s
      start_period: 5s
      retries: 3
  agent:
    build:
      context: .
      dockerfile: Dockerfile_Agent
    container_name: ai-infra-guard-agent
    environment:
      - TZ=Asia/Shanghai
      - AIG_SERVER=webserver:8088
      # 新增：Agent 也需要默认模型配置
      - OPENAI_MODEL=gpt-3.5-turbo
      - OPENAI_API_KEY=your_openai_api_key
      - OPENAI_BASE_URL=https://api.openai.com/v1
    networks:
      - ai-infra-guard-network
    restart: always
    depends_on:
      webserver:
        condition: service_healthy
networks:
  ai-infra-guard-network:
    driver: bridge
    name: ai-infra-guard-network